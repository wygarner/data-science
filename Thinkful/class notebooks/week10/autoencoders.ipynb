{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "<img src='https://miro.medium.com/max/3148/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png' width=70%>\n",
    "\n",
    "To demo what an autoencoder is doing, let's play a game of telephone that mirrors the encoding/decoding shown above.\n",
    "\n",
    "Person 1 is the first layer (colored blue), Person 2 is the second layer (colored green), ..., and Person 7 is the last layer (colored blue).\n",
    "\n",
    "## Encoding layer\n",
    "\n",
    "Person 1 will be our input layer, let's say our input data is a 10 word phrase (to match the number of blocks in the image).  Person 1 will tell Person 2 this 10 word phrase and Person 2's job is to figure out how to compress this phrase down to 8 words.\n",
    "\n",
    "Person 2 will then tell Person 3 this 8 word summarization of the origninal phrase.  Person 3 now has to summarize this phrase to 6 words.\n",
    "\n",
    "Person 3 passes this message to Person 4 who has to summarize down to 3 words.\n",
    "\n",
    "This 3 word summary is our encoded representation of our data.  It is a reduced dimension version of the data, the rest of the process (the decoder) is to figure out if this is a good summarization.\n",
    "\n",
    "## Decoding layer\n",
    "\n",
    "Person 4 (the code layer) tells their 3 word summary to Person 5.  Instead of summarizing, Person 5's job is to expand this summary into 6 words.\n",
    "\n",
    "Person 5 passes this expanded summary to Person 6 who expands it to 8 words and passes it along to our final Person 7 (the output layer).\n",
    "\n",
    "Person 7 expands the summary back to the original 10 words, and now we compare how close this output is to the input.  There's likely to be some loss of information.\n",
    "\n",
    "Our goal is to iterate on this game of telephone until Person 7 is able to recreate the input phrase as closely as possible.  If our output is very similar to our input, then the code layer has a very good summary of the input data.  We can use this lower dimension representation of our data thats found in the code layer for visualization/supervised learning.\n",
    "\n",
    "## Toy Example\n",
    "\n",
    "For example, this telphone phrase might be:\n",
    "\n",
    "An early iteration might be very bad at recreating the input:\n",
    "\n",
    "```\n",
    "Layer 1 / Input layer:  \"the rain in spain falls very neatly on the plain\"\n",
    "Layer 2:                \"the in falls very neatly on the plain\"\n",
    "Layer 3:                \"the in very neatly on the\"\n",
    "Layer 4 / Code layer:   \"the on the\"\n",
    "Layer 5:                \"puts the lotion on the skin\"\n",
    "Layer 6:                \"it puts the lotion on the skin or\"\n",
    "Layer 7 / Output layer: \"it puts the lotion on the skin or it gets\"\n",
    "```\n",
    "\n",
    "Our input phrase was very ESL and our output is Buffalo Bill.  This indicates that the code layer is a bad summary of the data.  The code layer has still performed dimension reduction, but it doesn't contain useful information.\n",
    "\n",
    "A later iteration will hopefully be better at learning the data.\n",
    "\n",
    "```\n",
    "Layer 1 / Input layer:  \"the rain in spain falls very neatly on the plain\"\n",
    "Layer 2:                \"rain in spain falls neatly on the plain\"\n",
    "Layer 3:                \"rain in spain falls on plain\"\n",
    "Layer 4 / Code layer:   \"rain spain plain\"\n",
    "Layer 5:                \"rain spain falls on the plain\"\n",
    "Layer 6:                \"rain in spain falls neatly on the plain\"\n",
    "Layer 7 / Output layer: \"rain in spain falls neatly on the great spain plain\"\n",
    "```\n",
    "\n",
    "We could now use the code layer (`\"rain spain plain\"`) to serve as a lower dimensional representation of our input data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
