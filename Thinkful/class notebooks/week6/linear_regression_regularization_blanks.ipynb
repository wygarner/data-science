{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Bikes ðŸš²\n",
    "\n",
    "[Lecture slides](https://docs.google.com/presentation/d/1lQ3AcIMXd1pNFiAroYExzLOLq2HGSWrJj0p8OL8vT8Q/edit#slide=id.p22)\n",
    "\n",
    "----\n",
    "\n",
    "The data from today is about bike sharing demand from [a previously held Kaggle competition](https://www.kaggle.com/c/bike-sharing-demand/data).  Below is a bit of documentation from the competition.\n",
    "\n",
    "---\n",
    "\n",
    "> You are provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.\n",
    ">\n",
    "> Data Fields\n",
    "> ```\n",
    "> datetime - hourly date + timestamp  \n",
    "> season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "> holiday - whether the day is considered a holiday\n",
    "> workingday - whether the day is neither a weekend nor holiday\n",
    "> weather - 1: Clear, \n",
    ">              Few clouds,\n",
    ">              Partly cloudy, \n",
    ">              Partly cloudy\n",
    ">           2: Mist + Cloudy, \n",
    ">              Mist + Broken clouds, \n",
    ">              Mist + Few clouds,\n",
    ">              Mist\n",
    ">           3: Light Snow,\n",
    ">              Light Rain + Thunderstorm + Scattered clouds, \n",
    ">              Light Rain + Scattered clouds\n",
    ">           4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, \n",
    ">              Snow + Fog \n",
    "> temp - temperature in Celsius\n",
    "> atemp - \"feels like\" temperature in Celsius\n",
    "> humidity - relative humidity\n",
    "> windspeed - wind speed\n",
    "> casual - number of non-registered user rentals initiated\n",
    "> registered - number of registered user rentals initiated\n",
    "> count - number of total rentals\n",
    "> ```\n",
    "\n",
    "From this list of column descriptions.\n",
    "\n",
    "* What columns are categorical?  Which of these do you think we'll need to one-hot-encode?\n",
    "* Do you see any columns that you expect to be multicollinear?\n",
    "\n",
    "In the Kaggle competition the challenge was to predict the `count` column.  The `casual` and `registered` columns aren't allowed to be used since that information is really just the `count` column broken out into its components (i.e. `count = casual + registered`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")\n",
    "\n",
    "\n",
    "def one_hot_encode(X, encode_cols, index=None):\n",
    "    other_cols = [c for c in X.columns if c not in encode_cols]\n",
    "\n",
    "    ct = ColumnTransformer(\n",
    "        #   Format\n",
    "        #   [(\"name of step\", what_to_do(), [what columns to do it to])]\n",
    "        [(\"one hot encode\", OneHotEncoder(drop=\"first\", sparse=False), encode_cols)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    ct.fit(X)\n",
    "\n",
    "    # This is not the flexible and definitely not the most\n",
    "    # readable way to get column names, a function would be better\n",
    "    encoded_names = ct.transformers_[0][1].get_feature_names()\n",
    "    encoded_names = list(encoded_names)\n",
    "\n",
    "    X_encoded = ct.transform(X)\n",
    "    X_encoded = pd.DataFrame(X_encoded, columns=encoded_names + other_cols, index=index)\n",
    "\n",
    "    for i, name in enumerate(encode_cols):\n",
    "        X_encoded.columns = X_encoded.columns.str.replace(f\"^x{i}\", name)\n",
    "\n",
    "    return X_encoded\n",
    "\n",
    "\n",
    "def eval_preds(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "\n",
    "    rmse = np.sqrt((error ** 2).mean())\n",
    "    mae = error.abs().mean()\n",
    "    mape = (error / y_true).abs().mean()\n",
    "\n",
    "    print(f\"rmse {rmse:.2f}\")\n",
    "    print(f\"mae {mae:.2f}\")\n",
    "    print(f\"mape {mape:.2f}\")\n",
    "\n",
    "    line_pts = [y_true.min(), y_true.max()]\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    plt.plot(line_pts, line_pts, c=\"red\", ls=\"--\", alpha=0.5)\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Fit\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Let's do some general EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# data from https://www.kaggle.com/c/bike-sharing-demand/data\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1GJrx_Y3cvD1sWLg_zF_mMZZ0iZ_If2E02VIkyCi3PTc/export?format=csv\"\n",
    "bike_sharing = pd.read_csv(data_url)\n",
    "bike_sharing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `datetime` itself isn't very useful.  Why is that and how might we get some useful info out of the column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the column datatypes to make sure there's nothing unexpected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have missing values we need to handle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate summary statistics.  When doing this, pay extra attention to our response variable, `count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Plot a `scatter_matrix`/`pairplot` of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to point out.\n",
    "\n",
    "* Its not the strongest thing, but, temperature seems to have an effect on rentals (the higher the temp the more rentals).  This effect seems more prominent in the casual rentals.\n",
    "* Both humidity and windspeed seem to have negative effects.  When they're low, there doesn't seem to be a big correlation, but when these factors are high we see a drop off in rentals.\n",
    "* We won't be using this information, but note the plots between casual & count.  We see a pretty distinct v-shape, this is indicative of an interaction happening somewhere.  That is, there seems to be 2 distinct groups of data, we could try and explore and find a reason for this split.\n",
    "* Our response variable `count` is a very positively skewed distribution.  This indicates that we might want to perform a transformation to it.  For now we'll leave it, and come back to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bike_sharing[\"count\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot of our response variable also shows some outliers we might want to deal with.  This is something we might come back to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Prep data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "One-hot encode features where appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"season\", \"weather\", \"weekday\", \"hour\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Separate data into its `X` and `y` components, and perform a `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Assess multicollinearity with variance inflation factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Address any issues with collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a ridge regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a plain ole `LinearRegression` model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a fancy ole Ridge regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation of ridge regression to see that score here is R^2\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "print(f\"LinearRegression Train R^2: {linear.score(X_train, y_train):.2f}\")\n",
    "print(f\"LinearRegression Test R^2: {linear.score(X_test, y_test):.2f}\")\n",
    "\n",
    "print(f\"\\nRidge Train R^2: {ridge.score(X_train, y_train):.2f}\")\n",
    "print(f\"Ridge Test R^2: {ridge.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real change in our $R^2$ here.. whats the deal man? I thought this was used to make things better.  Remember what the loss function is doing.  We're including a penalty for large coefficients, so let's see how they changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(linear.coef_ ** 2))\n",
    "print(np.sum(ridge.coef_ ** 2))\n",
    "\n",
    "print(linear.coef_)\n",
    "print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's actually see numbers other than $R^2$.  How are our predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ridge.predict(X_train)\n",
    "y_pred_test = ridge.predict(X_test)\n",
    "\n",
    "print(\"Train\\n---------------------------------\")\n",
    "eval_preds(y_train, y_pred_train)\n",
    "print(\"Test\\n---------------------------------\")\n",
    "eval_preds(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to fall evenly around that line.  Right now, we're underpredicting high values.  In our EDA we made a comment about our response's skewed distribution.  We might want to reconsider a transformation.  A log transformation is a good one to start with for right skewed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit the model on a logged version of `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = _____\n",
    "y_pred_test = _____\n",
    "\n",
    "print(\"Train\\n---------------------------------\")\n",
    "print(f\"R^2: {ridge.score(X_train, np.log(y_train)):.2f}\")\n",
    "eval_preds(y_train, y_pred_train)\n",
    "print(\"Test\\n---------------------------------\")\n",
    "print(f\"R^2: {ridge.score(X_test, np.log(y_test)):.2f}\")\n",
    "eval_preds(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a LASSO regression model ðŸ¤ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are our coefficients looking now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... the coefficient shrinking definitely did its thing here... We probably want a better way of selecting an alpha than guess and check.  This is where cross validation comes into play paired with something called a gridsearch.  All the grid search does is find the best combination of hyperparameters that we tell it to test.  Here our only hyperparameter will be alpha.\n",
    "\n",
    "Let's fit lasso using a gridsearch for the best alpha.  After we fit the model lets view the best alpha and the new coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ____\n",
    "\n",
    "lasso_cv = GridSearchCV(Lasso(), grid, verbose=1)\n",
    "lasso_cv\n",
    "\n",
    "# The best fit is in the best_estimator_ attribute\n",
    "print(f\"selected alpha: {lasso_cv.best_estimator_.alpha}\")\n",
    "lasso_cv.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ____\n",
    "y_pred_test = ____\n",
    "\n",
    "print(\"Train\\n---------------------------------\")\n",
    "print(f\"R^2: {lasso_cv.score(X_train, np.log(y_train)):.2f}\")\n",
    "eval_preds(y_train, y_pred_train)\n",
    "print(\"Test\\n---------------------------------\")\n",
    "print(f\"R^2: {lasso_cv.score(X_test, np.log(y_test)):.2f}\")\n",
    "eval_preds(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now on par with the ridge regression results.  Not the most fair comparison though, with ridge regression we didn't grid search, we just made up a value for alpha.  On your own you can implement grid search for the ridge regression and see how/if the results improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an elasticnet regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ____\n",
    "elasticnet_cv = GridSearchCV(ElasticNet(), grid, verbose=1)\n",
    "elasticnet_cv.fit(X_train, np.log(y_train))\n",
    "\n",
    "print(f\"selected alpha: {elasticnet_cv.best_estimator_.alpha}\")\n",
    "print(f\"selected l1_ratio: {elasticnet_cv.best_estimator_.l1_ratio}\")\n",
    "elasticnet_cv.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The l1_ratio selected was 1.0... what does this mean?  (the answer to this question is also the reason why there's no analysis on the model results)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
