{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Szeged*, Hungary Weather\n",
    "\n",
    "This notebook is gonna walk through an analysis of weather data from Szeged*, Hungary.  The analysis will lead up to a linear regression model that predicts temperature.\n",
    "\n",
    "<sub>*(according to every submitted pronunciation [here](https://forvo.com/word/szeged/), the city is pronounced kinda like 'sehged')</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But first!  Warm up ü•µ\n",
    "\n",
    "* Q: How does the ROC curve differ in binary and multi-class classification?\n",
    "  * A: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n",
    "  \n",
    "* Bonus warm-up ü•µ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "\n",
    "# Gen data\n",
    "n = 5000\n",
    "y = np.random.choice([0, 1, 2], n)\n",
    "x1 = np.random.normal(10, 5, n)\n",
    "x2 = np.random.normal(5, 3, n)\n",
    "\n",
    "# Shift xs by class to make more easily separable\n",
    "x1[np.where(y == 0)] += 5\n",
    "x1[np.where(y == 1)] -= 5\n",
    "x2[np.where(y == 0)] += 5\n",
    "x2[np.where(y == 2)] -= 5\n",
    "\n",
    "df = pd.DataFrame({\"x1\": x2, \"x2\": x1, \"y\": y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot `x1` by `x2` and color by `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform a train/test split with 20% of the data in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit a logistic regression model (use whatever hyperparameters you'd like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Score your model and report fitting issues (i.e. under/over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display a confusion matrix and a classification report.\n",
    "  * When classifying an actual class 0, what mistake is the model most likely to make?\n",
    "  * What 2 classes are the hardest to separate? Does this make sense based on the scatter plot?\n",
    "  * What class has the highest recall? What does that mean? Does this make sense based on the scatter plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Really general EDA\n",
    "\n",
    "We'll start with loading the data and doing some intro EDA.  Just things like `shape`, `head`, `isnull`, etc...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import plotly_express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# CSV downloaded from https://www.kaggle.com/budincsevity/szeged-weather\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1VI1rDsUI7KTMUEyDgV8cc0gLdwYr1p_aCwyyp3Mz3_M/edit?usp=sharing\"\n",
    "szeged = pd.read_csv(data_path)\n",
    "szeged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Let's go on a tangent investigating these `NA`s!\n",
    "\n",
    "### Tangent start\n",
    "\n",
    "*click here to jump to [Tangent end](#Tangent-end)*\n",
    "\n",
    "My guess going in would be that a lack of precipitation would appear as an `NA` here, but that's a suspiciously low percentage for a lack of precipitation.  I will concede, I'm not familiar with Hungary's weather, maybe it does rain there 99.5% of the time.\n",
    "\n",
    "We could:\n",
    "  * Drop them.. It's a low percentage of our records, but maybe there's value to be had?\n",
    "  * look at the data's documenation (should probably start here... but we won't...)\n",
    "  * look at the `value_counts` of the `Precip Type` column.\n",
    "  * look at the other column values when `Precip Type` is `NA`\n",
    "  * Look at a `crosstab` of `Precip Type` and a column like `Summary`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the value counts of the `Precip Type` column, use an argument to avoid excluding NaN from this output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the head of the data when `Precip Type` is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at a `crosstab` of `Precip Type` and a column like `Summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "A higher percentage of `NaN`s seem to be associated with clear weather than rain or snow.  It feels safe to conclude there's some relationship between `NaN`s and lack of precipitation.  We can confirm this by checking the documentation.  If we check the [Kaggle page](https://www.kaggle.com/budincsevity/szeged-weather) where this data was downloaded from, we see that this data was originally collected from the [darksky.net](https://darksky.net/) API.  Conveniently, this API has [some documentation](https://darksky.net/dev/docs#data-point-object) on all the values it can return.  The below is copied from the documentation about our `Precip Type` column.  So we see that if the `precipIntensity` is zero, we are expected to have a `NaN`.\n",
    "\n",
    "> **`precipType`** *optional*\n",
    ">\n",
    "> The type of precipitation occurring at the given time. If defined, this property will have one of the following values: `\"rain\"`, `\"snow\"`, or `\"sleet\"` (which refers to each of freezing rain, ice pellets, and ‚Äúwintery mix‚Äù). (If `precipIntensity` is zero, then this property will not be defined. Additionally, due to the lack of data in our sources, historical `precipType` information is usually estimated, rather than observed.)\n",
    "\n",
    "### Tangent end\n",
    "\n",
    "Okie doke. Let's get down to brass tacks.  We want to predict temperature.  To do this we'll just use the `Humidity` and `Visibility (km)` features.  We can start to focus our EDA on these culprits.\n",
    "\n",
    "Subset the dataframe to only the temp (C), humidity, and visibility columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pairplot/scatter matrix of all three remaining columns. Do we see some correlations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a heatmap of the correlations between these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have some predictive power within these two inputs.  Looking at the scatterplots we can see trends, and a heatmap confirms some correlation.  `Humidity` is more tightly coupled with `Temperature (C)` than `Visibility (km)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a train test split; pick whatever parameters you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression model using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the model and report fitting issues (i.e. under/over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model's formula can be found in the `intercept_` and `coef_` attributes.  The trailing underscore is a convention in `sklearn` to mean the model's `fit` method will define them (i.e. we our model can't have coefficients until the model is fit, so they're stored in a trailing `_` attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use string interpolation/formating to print out a string version of our linear regression model's formula\n",
    "  * i.e. this might look like `Temp = 100 + (20) * Humidity + (2) * Visibility`\n",
    "\n",
    "\n",
    "What does this formula tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model object's predict method to make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the input features, `y_test`, and the predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a plot of our predictions vs our predictors.\n",
    "\n",
    "Make a scatter plot with Humidity on the x axis and model predictions as the y axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatter plot with Visibility on the x axis and model predictions as the y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not very linear... Although linear regression is making 'linear combinations' of our variables, the output isn't a line when we have multiple predictors. Our current data has 3 dimensions (2 features and 1 target), so we'll need a visualization that can capture all 3 to fully make sense of it.  Color is a nice goto way to cheat 3 dims into a 2d plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatter plot with Humidity on the x axis, model predictions as the y axis, and color by visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatter plot with visibility on the x axis, model predictions as the y axis, and color by Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of 3d, we can actually plot this directly.  Note, 3d plots do not always provide more insight than a series of 2d plots; make sure to evaluate your use case on whether or not it fits.  Here, I think 3d plots help drive home the point that we have a plane of predictions.  When we get above 3d this gets harder and harder to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.scatter_3d(\n",
    "    data_frame=pred_df, x=\"Humidity\", y=\"Visibility (km)\", z=\"y_pred\"\n",
    ")\n",
    "\n",
    "# Include actuals? (un)comment to toggle\n",
    "figure.update_traces(name=\"Predicted\", showlegend=True)\n",
    "figure.add_scatter3d(\n",
    "    x=pred_df[\"Humidity\"],\n",
    "    y=pred_df[\"Visibility (km)\"],\n",
    "    z=pred_df[\"y_true\"],\n",
    "    opacity=0.2,\n",
    "    mode=\"markers\",\n",
    "    name=\"Actuals\",\n",
    ")\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In later lessons we'll look more into model assumptions, evaluation, and interpretation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
