{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè¢ Chicago Salaries üí∞\n",
    "\n",
    "Chicago has public data on many job salaries of public servant type roles.  This data can be found [here](https://data.cityofchicago.org/Administration-Finance/Current-Employee-Names-Salaries-and-Position-Title/xzkq-xp2w).\n",
    "\n",
    "### Warm Up ü•µ\n",
    "\n",
    "* What are C and epsilon used for in SVR?\n",
    "\n",
    "----\n",
    "\n",
    "#### Boosting üöÄ\n",
    "\n",
    "Boosting is an 'ensembling' technique.\n",
    "\n",
    "What does ensembling mean in the context of machine learning?\n",
    "\n",
    "In boosting, we'll iteratively build models (aka build models in a series; aka build one model after another). The overview is.\n",
    "\n",
    "1. Build a pretty dumb model (more typically called a 'weak learner')\n",
    "   * In the image doing classification, this is the first grid\n",
    "* See where that model makes mistakes\n",
    "* Build another model with a focus on not making the same mistakes again\n",
    "   * In the image, this is the second/third grids.  The mistakes are enlarged in these to show that they're a priority.\n",
    "* Repeat steps 1-3 as much as you want\n",
    "* Combine the output of these models somehow\n",
    "   * In the image, this is the final grid.\n",
    "\n",
    "\n",
    "<img src='https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2019/06/How-Does-Boosting-Algorithm-Work-Boosting-Machine-Learning-Edureka-min-528x254.png' width='50%'>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image is more focused on boosting in a regression setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align='center'><img src='https://i.imgur.com/RewteYv.png' width=70%></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gender_guesser\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from gender_guesser.detector import Detector\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a direct link to the published data.\n",
    "# The data might change (last updated Oct 2019)\n",
    "# The data might be moved and this link might break\n",
    "# A snapshot of the data can be found on kaggle:\n",
    "# https://www.kaggle.com/chicago/chicago-citywide-payroll-data\n",
    "\n",
    "# The commentary in this notebook also falls out of date pretty quickly... sorry\n",
    "data_url = (\n",
    "    \"https://data.cityofchicago.org/api/views/xzkq-xp2w/rows.csv?accessType=DOWNLOAD\"\n",
    ")\n",
    "chicago = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some general 'get to know you' EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't already run an `np.nan` check, do one now to show the percent of missing values by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those percents look suspiciously related...\n",
    "\n",
    "Let's say we want to only predict salary, drop hourly data from the dataset and re-check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the missing values were directly related to the `'Salary or Hourly'` distinction.  We can now drop some columns that don't give us any info going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"Salary or Hourly\", \"Typical Hours\", \"Hourly Rate\"]\n",
    "chicago = chicago.drop(columns=drop_cols)\n",
    "chicago.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All categorical variables... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the dataframe to just full-time workers and drop the `'Full or Part-Time'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideOutput": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any NAs remaining in the salary column, drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, names aren't too informative for prediction.  BUT! We don't have a lot of features here, we probably want to put our feature engineering hats on.\n",
    "\n",
    "* Maybe we wanted to investigate nepotism, if that was the case, name could be valuable and we might want to restrict to surname...\n",
    "* Maybe we want to investigate if there's a gender pay gap in our data.  To do this we might try and guess the gender of the person based on their first name.  This, of course, won't be amazingly accurate... but it's kind of neat that we can do this.\n",
    "    * Note, this type of feature is definitely a bit of a stretch, we're almost surely introducing some bias.  This type of feature might not be to good to use in practice unless you're wanting to do some analysis that can generate clicks but might not have the strongest backing.  \n",
    "\n",
    "Let's go down this maybe ill advised rabbit trail of engineering a gender column.\n",
    "\n",
    "First, we need to isolate first name.  Below are some example names in the form we'll be working with in the dataframe. However, before we think about doing this in pandas, let's figure out how to isolate the name in a string.  \n",
    "\n",
    "Write some code to extract the first names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ADRIANO,  RACQUEL ANNE\"  # Expected output: 'RACQUEL'\n",
    "# name = 'AFFANEH,  MAHIR A'       # Expected output: 'MAHIR'\n",
    "# name = 'SPANNBAUER, ADAM M'      # Expected output: 'ADAM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now translate this to pandas and apply it to the `'Name'` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prolly want this as a function so we can hide away all this logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_name(chitown_names):\n",
    "    # some awesome pandas code here\n",
    "    return first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago[\"First Name\"] = get_first_name(chicago[\"Name\"])\n",
    "chicago.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to classify these as male/female... A couple ways we could do this:\n",
    "\n",
    "* Find a database (like Social Security or something idk) of names by gender and look up the names and label with the most common\n",
    "* Use a model trained on a database like this to make predictions\n",
    "   * ^One of those is `pip` installable (`!pip install gender_guesser`)\n",
    "   \n",
    "Below is an example on how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gender_guesser.detector import Detector\n",
    "\n",
    "gd = Detector()\n",
    "print(\"Title case:\")\n",
    "print(gd.get_gender(\"Candy\"))\n",
    "print(gd.get_gender(\"Scott\"))\n",
    "print(gd.get_gender(\"Tonks\"))  # my dog's name (she's a lady)\n",
    "\n",
    "# It doesn't know how to handle casing...\n",
    "print(\"\\nUpper case:\")\n",
    "print(gd.get_gender(\"CANDY\"))\n",
    "print(gd.get_gender(\"SCOTT\"))\n",
    "print(gd.get_gender(\"TONKS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change our first names to title case to get predictions it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example in string land\n",
    "'THE GREAT GATSBY'.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply title casing the the first names in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago['First Name'] = chicago['First Name'].___._____\n",
    "chicago.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named `'gender_guess'` by applying the `gd.get_gender` to the title cased first name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago[\"gender_guess\"] = chicago[\"First Name\"]._____(____________)\n",
    "chicago.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now drop our name columns (unless we (1) wanted to investigate nepotism, (2) check if bradley's make more money, or something else name related)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"Name\", \"First Name\"]\n",
    "chicago = chicago.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a violin plot of `'Annual Salary'` by `'gender_guess'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, of course, the very often forgotten gender, 'andy'.\n",
    "\n",
    "Per documentation, andy is their shorthand for androgynous.  Let's collapse down to 3 categories: male, female, other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    \"mostly_male\": \"male\",\n",
    "    \"mostly_female\": \"female\",\n",
    "    \"unknown\": \"other\",\n",
    "    \"andy\": \"other\",\n",
    "}\n",
    "\n",
    "chicago[\"gender_guess\"] = chicago[\"gender_guess\"].replace(replacements)\n",
    "\n",
    "sns.violinplot(\"Annual Salary\", \"gender_guess\", data=chicago)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our plot we might be seeing a gender pay gap, with the biggest loser being... Andy.  At least Andy has Woody and Buzz to help cope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí•BOOM üí• new feature is now engineered.  Let's get back to some more on topic stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the value counts for `'Job Titles'` and `'Department'`.  Spoiler, there's a lot, create an 'other' category for both.  Decide some cutoff point for what's too few (threshold by count, threshold by count percentile, take the top n, etc.)\n",
    "\n",
    "* Perform the process on one of the columns\n",
    "* Translate this logic into a function\n",
    "* Use your function on the other column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a train test split stratified by our gender guess feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = chicago.dropna().drop(columns=[\"Annual Salary\"])\n",
    "y = chicago.dropna()[\"Annual Salary\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=chicago[\"gender_guess\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `X` data is all categories; let's use the `LeaveOneOutEncoder()`.  If we get poor performance we can come back and drop in a `OneHotEncoder()` with fairly little effort.\n",
    "\n",
    "* Complete the `Pipeline`\n",
    "    * Fill in the category encoder\n",
    "    * Fill in the gradient boosted regressor\n",
    "* Fit the pipeline to the training data\n",
    "* Report the scores for the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "pipeline = Pipeline([\n",
    "    (\"encode_cats\", _____),\n",
    "    (\"gbr\", ____)\n",
    "])\n",
    "# fmt: on\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"train_score {train_score}\")\n",
    "print(f\"test_score {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretty smart guy said this is his parameter grid for this model type. (the names don't line up with sklearn's names).\n",
    "\n",
    "<img src='https://i.stack.imgur.com/9GgQK.jpg' width='70%'>\n",
    "\n",
    "* Grid search some hyperparams to increase performance\n",
    "* Print out the best parameters from the CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted max_features/max_depth to have smaller grid\n",
    "grid = {\n",
    "    \"gbr__subsample\": _____,\n",
    "    \"gbr__max_features\": _____,\n",
    "    \"gbr__max_depth\": _____,\n",
    "}\n",
    "\n",
    "n_trees = 100\n",
    "learning_rate = 2 / n_trees\n",
    "\n",
    "# fmt: off\n",
    "pipeline = Pipeline([\n",
    "    (\"encode_cats\", LeaveOneOutEncoder()),\n",
    "    (\"gbr\", GradientBoostingRegressor(n_estimators=n_trees, \n",
    "                                      learning_rate=learning_rate))\n",
    "])\n",
    "# fmt: on\n",
    "\n",
    "pipeline_cv = GridSearchCV(pipeline, grid, verbose=1)\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the train and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = pipeline_cv.score(X_train, y_train)\n",
    "test_score = pipeline_cv.score(X_test, y_test)\n",
    "\n",
    "print(f\"train_score {train_score}\")\n",
    "print(f\"test_score {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the `.feature_importances_` from the gbtree regressor in your pipeline.  What was most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
