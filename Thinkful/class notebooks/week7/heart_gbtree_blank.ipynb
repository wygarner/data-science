{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❤️ Heart Disease 🤒\n",
    "\n",
    "The data today is from the [Framingham Heart Study](https://www.framinghamheartstudy.org/).  Below excerpt from [their wikipedia page](https://en.wikipedia.org/wiki/Framingham_Heart_Study):\n",
    "\n",
    "> The Framingham Heart Study is a long-term, ongoing cardiovascular cohort study of residents of the city of Framingham, Massachusetts. The study began in 1948 with 5,209 adult subjects from Framingham, and is now on its fourth generation of participants. Prior to the study almost nothing was known about the epidemiology of hypertensive or arteriosclerotic cardiovascular disease. Much of the now-common knowledge concerning heart disease, such as the effects of diet, exercise, and common medications such as aspirin, is based on this longitudinal study.\n",
    "\n",
    "### Warm-up 🥵\n",
    "\n",
    "Warm-up warm-ups\n",
    "* Describe what boosting is.\n",
    "* How do random forests avoid overfitting?\n",
    "\n",
    "Actual warm-up\n",
    "* How do we use residuals in gradient boosted trees?\n",
    "* How do we avoid overfitting in gradient boosted trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# p much in practice:\n",
    "# *if you want to use GradientBoostingClassifier\n",
    "#     * use XGBClassifier instead\n",
    "# *if you want to use GradientBoostingRegressor\n",
    "#     * use XGBRegressor instead\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1Tx7KJ7iW8IkiU-aERYFXsKvDsbFJbr80POW_2DyuYGQ/export?format=csv\"\n",
    "heart = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do basic EDA to get familiar with this heart data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be the impact of dropping NAs?\n",
    "* Calculate the percentage of rows that would remain after dropping NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have balanced classes?  If our model gets 85% accuracy, should we consider that good?\n",
    "* Calculate percentages of each class using `value_counts` and the `normalize` argument\n",
    "* Show a bar plot of the counts of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our data with respect to our target variable, `'TenYearCHD'`.  We actually have a lot of categorical variables here that are already encoded as numbers for us. We might consider re-encoding education, but it's already encoded as ordinal, let's keep it as is and come back if we think it will help.\n",
    "\n",
    "However, it might make more sense to visualize these as categorical rather than continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"education\"]\n",
    "\n",
    "bin_cols = [\n",
    "    \"male\",\n",
    "    \"currentSmoker\",\n",
    "    \"BPMeds\",\n",
    "    \"prevalentStroke\",\n",
    "    \"prevalentHyp\",\n",
    "    \"diabetes\",\n",
    "]\n",
    "\n",
    "# Grouping binary with other categorical for viz\n",
    "all_cat_cols = cat_cols + bin_cols\n",
    "\n",
    "num_cols = [\n",
    "    \"age\",\n",
    "    \"cigsPerDay\",\n",
    "    \"totChol\",\n",
    "    \"sysBP\",\n",
    "    \"diaBP\",\n",
    "    \"BMI\",\n",
    "    \"heartRate\",\n",
    "    \"glucose\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What's an appropriate chart type to plot our categorical variables with our categorical target variable?\n",
    "* Write a `for` loop to iterate over the categorical column names (in `all_cat_cols`)\n",
    "* Show a plot of `'TenYearCHD'` with each of the categorical variables.\n",
    "* Use the target as the main variable and color by the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What's an appropriate chart type to plot our continuous variables with our categorical target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart.drop(columns=[\"TenYearCHD\"])\n",
    "y = heart[\"TenYearCHD\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a `ColumnTransformer` to scale the numeric columns\n",
    "   * Leave the remaining columns untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "preprocessing = ColumnTransformer([\n",
    "    ____\n",
    "], ____)\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a `Pipeline` with:\n",
    "    * the `ColumnTransformer` preprocessing as the first step\n",
    "    * an `XGBClassifier` as the second step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "pipeline = Pipeline([\n",
    "    ____,\n",
    "    ____\n",
    "])\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit the pipeline to the training data with the default params\n",
    "\n",
    "\n",
    "* What is the overall accuracy?\n",
    "* Are we overfitting?\n",
    "* Is this a good accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score}\")\n",
    "print(f\"Test score: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How are we making mistakes?\n",
    "  * Show a `confusion_matrix` and a `classification report`\n",
    "* In the context of the problem, what kind of mistake is the worst to make?\n",
    "   * Mistake 1: Tell someone they're at risk when they're not\n",
    "   * Mistake 2: Tell someone they're not at risk when they are\n",
    "* Based on that, what number from a `classification_report` are we most interested in?\n",
    "   * Do we want to maximize or minimize this value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try a grid search to see if we get better performance with better parameters.\n",
    "\n",
    "<img src='https://i.stack.imgur.com/9GgQK.jpg' width='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation of main parameters of interest:\n",
    "* Name in table - `xgb_parameter_name`\n",
    "\n",
    "---\n",
    "\n",
    "* \\# of Trees - `n_estimators`\n",
    "* Learning Rate - `learning_rate`\n",
    "* Row Sampling - `subsample`\n",
    "* Column Sampling - `colsample_bytree`\n",
    "* Max Tree Depth - `max_depth`\n",
    "\n",
    "---\n",
    "\n",
    "* Set up a grid search using this pictured slide as guidance\n",
    "* What were the best params according to this search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted max_features/max_depth to have smaller grid\n",
    "params = {\n",
    "    \"____\": [0.5, 0.75, 1.0],\n",
    "    \"____\": [0.5, 0.75, 1.0],\n",
    "    \"____\": [5, 7, 10],\n",
    "}\n",
    "\n",
    "n_trees = 100\n",
    "learning_rate = 2 / n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv = GridSearchCV(pipeline, params, verbose=1, cv=2)\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How does this affect our performance?\n",
    "* Would we want to deploy this model to predict heart disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = pipeline_cv.score(X_train, y_train)\n",
    "test_score = pipeline_cv.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score}\")\n",
    "print(f\"Test score: {test_score}\\n\")\n",
    "\n",
    "y_pred = pipeline_cv.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're having a lot of trouble with this class imbalance problem, our model is really biased towards predicting the negative class because most the time it would be correct to do so.\n",
    "\n",
    "There are strategies for dealing with class imbalance, and some common ones that aren't too bad to use are listed out here: https://elitedatascience.com/imbalanced-classes.\n",
    "\n",
    "Let's look into an sampling approach to balance the classes in our training set.\n",
    "\n",
    "* Separate the training data into 2 dataframes:\n",
    "    * One with the majority class\n",
    "    * One with the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many rows does each have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use sampling to make both sides of the story have the same number of rows\n",
    "    * 'Up sample' with replacement for the minority class\n",
    "    * 'Down sample' without replacement for the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Redefine `X_train` and `y_train` with your resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Refit the same GridSearchCV object but with this new training data\n",
    "* Print out the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"xgb__subsample\": [0.5, 0.75, 1.0],\n",
    "    \"xgb__max_features\": [0.5, 0.75, 1.0],\n",
    "    \"xgb__max_depth\": [3, 4, 5],\n",
    "}\n",
    "\n",
    "n_trees = 100\n",
    "learning_rate = 2 / n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv = GridSearchCV(pipeline, params, verbose=1, cv=2)\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the performance better? worse? different at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = pipeline_cv.score(X_train, y_train)\n",
    "test_score = pipeline_cv.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score}\")\n",
    "print(f\"Test score: {test_score}\\n\")\n",
    "\n",
    "y_pred = pipeline_cv.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
