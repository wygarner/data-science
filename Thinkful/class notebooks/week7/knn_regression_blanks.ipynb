{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regression\n",
    "\n",
    "### Warm-up ðŸ¥µ\n",
    "\n",
    "* How are weights implemented in K Nearest Neighbors?\n",
    "  * By default in `sklearn` (aka the `'uniform'` option)?\n",
    "  * When using the `'distance'` option in `sklearn`?\n",
    "  \n",
    "* What type of machine learning problem were we using KNN on up until now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and General EDA ðŸš—\n",
    "\n",
    "We'll be looking at the auto MPG dataset from UCI.  Which can be found [here](https://archive.ics.uci.edu/ml/datasets/auto+mpg).  From the description we see:\n",
    "\n",
    "1. mpg: continuous\n",
    "2. cylinders: multi-valued discrete\n",
    "3. displacement: continuous\n",
    "4. horsepower: continuous\n",
    "5. weight: continuous\n",
    "6. acceleration: continuous\n",
    "7. model year: multi-valued discrete\n",
    "8. origin: multi-valued discrete\n",
    "9. car name: string (unique for each instance)\n",
    "\n",
    "Our target variable will be `mpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original\"\n",
    "names = [\n",
    "    \"mpg\",\n",
    "    \"cylinders\",\n",
    "    \"displacement\",\n",
    "    \"horsepower\",\n",
    "    \"weight\",\n",
    "    \"acceleration\",\n",
    "    \"year\",\n",
    "    \"origin\",\n",
    "    \"model\",\n",
    "]\n",
    "\n",
    "# '\\s+' means \"more than 1 space\" you can download the\n",
    "# data from the data_url to inspect the data and see why this makes sense\n",
    "auto = pd.read_csv(data_url, sep=\"\\s+\", names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some *really* general eda.  i.e just stuff like shape/head/info/describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display rows with any NAs in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Engineering\n",
    "\n",
    "### Handling NAs\n",
    "\n",
    "Since our target variable is `mpg` we probably don't want to do any imputation strategy on it.  We should drop NAs in the target unless we have some domain expertise that tells us otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `horsepower` column is responsible for the rest of the NAs.  In practice, we might look up this info somehow, but that would probably take too much time for this demo.\n",
    "\n",
    "So how do you want to handle these? by dropping? with imputation?  If imputing, what should we impute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Variables\n",
    "\n",
    "* From the description of the columns above, we can see that `origin` should is a 'discrete' value.\n",
    "* The `model` column is also a categorical variable\n",
    "* You can also see that `year` is 'discrete' from the description, but in practice we'll treat year variables as ordinal, so we don't need to make any changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the value counts for each of our categorical columns (don't include year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For origin, this is a pretty easy decision, let's one-hot encode and move on.  We're deciding to one-hot encode instead of leaving it as oridinal, because we have no reason to believe that the origin is ordinal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model category is a little trickier... Most of the model categories have only 1 value (we have 305 categories for our 406 rows).  This level of variation wouldn't be too useful.  What is a feature we could engineer from this column though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a train/test split with 20% of the data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto.drop(columns=[\"mpg\", \"model\"])\n",
    "y = auto[\"mpg\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build... a modeling pipeline for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"origin\", \"make\"]\n",
    "drop_cats = [1, \"other\"]\n",
    "\n",
    "# The rest are numeric\n",
    "num_cols = [c for c in X if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = pipeline_cv.score(X_train, y_train)\n",
    "test_score = pipeline_cv.score(X_test, y_test)\n",
    "\n",
    "print(f\"train_score: {train_score}\")\n",
    "print(f\"test_score: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to linear regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
