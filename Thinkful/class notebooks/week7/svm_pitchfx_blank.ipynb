{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚾ PITCHf/x ⚾\n",
    "\n",
    "PITCHf/x is a system developed by Sportvision and introduced in Major League Baseball (MLB) during the 2006 playoffs. It uses two cameras to record the position of the pitched baseball during its flight from the pitcher’s hand to home plate, and various parameters are measured and calculated to describe the trajectory and speed of each pitch. It is now instituted in all ballparks in MLB.\n",
    "\n",
    "This version of the data used was downloaded from the `.Rdata` file provided on [this page](https://www2.stat.duke.edu/courses/Summer17/sta101.001-2/uploads/project/project.html) (direct link to [`.Rdata` file](http://stat.duke.edu/courses/Summer17/sta101.001-2/uploads/project/mondayBaseball.Rdata)).  There is also a full data dictionary on [this page](https://www2.stat.duke.edu/courses/Summer17/sta101.001-2/uploads/project/project.html).  There are many other ways to gather the data as shown in ['A new Python-based PITCHf/x parser & scraper'](https://www.beyondtheboxscore.com/2015/9/24/9374949/a-new-python-based-pitchf-x-parser-scraper) by John Choiniere.\n",
    "\n",
    "We'll specifically be looking into predicting `pitchType`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1pmBtSw7v_tU_dIX1-4E8_Q7wC43fDs6LGDQzN49-ffk/export?format=csv\"\n",
    "pitch = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some initial EDA to get familiar with what data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of data.  We're going to take the easy way out and drop all the missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = pitch.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of id type columns that aren't too useful for general predictions of `pitchType`.  Sure, what pitcher is throwing the ball would probably be predictive, but we want our model to work years down the road when these pitchers might not be playing anymore.  If we were wanting to update our model very often, then including pitcher might be a good feature.\n",
    "\n",
    "Drop the id columns from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\n",
    "    \"gameString\",\n",
    "    \"gameDate\",\n",
    "    \"visitor\",\n",
    "    \"home\",\n",
    "    \"batterId\",\n",
    "    \"batterName\",\n",
    "    \"pitcherId\",\n",
    "    \"pitcherName\",\n",
    "    \"catcherId\",\n",
    "    \"catcher\",\n",
    "    \"umpireId\",\n",
    "    \"umpire\",\n",
    "]\n",
    "\n",
    "pitch = _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have essentially 3 classes of columns now:\n",
    "\n",
    "* Before pitch - stats about batter handedness etc.\n",
    "* After pitch - metrics about pitch speed etc.\n",
    "* After hit - metrics about what angle the ball was hit at etc.\n",
    "\n",
    "Let's say we're making our predictions for a broadcasting company.  Our broadcast wants to automatically display on the screen what the pitch was based on metrics we get instantaneously about the pitch's speed/movement.\n",
    "\n",
    "Based on this, we wouldn't want to include metrics that happen after a hit. Drop the after hit columns from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_pitch_cols = [\n",
    "    \"inning\",\n",
    "    \"side\",\n",
    "    \"balls\",\n",
    "    \"strikes\",\n",
    "    \"outs\",\n",
    "    \"batterHand\",\n",
    "    \"batterPosition\",\n",
    "    \"pitcherHand\",\n",
    "    \"timesFaced\",\n",
    "]\n",
    "\n",
    "after_pitch_cols = [\n",
    "    \"releaseVelocity\",\n",
    "    \"spinRate\",\n",
    "    \"spinDir\",\n",
    "    \"locationHoriz\",\n",
    "    \"locationVert\",\n",
    "    \"movementHoriz\",\n",
    "    \"movementVert\",\n",
    "]\n",
    "\n",
    "after_hit_cols = [\n",
    "    \"probCalledStrike\",\n",
    "    \"battedBallType\",\n",
    "    \"battedBallAngle\",\n",
    "    \"battedBallDistance\",\n",
    "    \"paResult\",\n",
    "    \"pitchResult\",\n",
    "]\n",
    "\n",
    "pitch = pitch.drop(columns=after_hit_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the `head` of the dataframe again, we cutout a lot of columns so this is a much more managable view of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict the `pitchType`.  A dictionary has been created below to translate the abbreviations into a longer/more readable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_abbr = {\n",
    "    \"FT\": \"fastball (two-seam)\",\n",
    "    \"FF\": \"fastball (four-seam)\",\n",
    "    \"FC\": \"fastball (cutter)\",\n",
    "    \"FS\": \"fastball (splitter)\",\n",
    "    \"SI\": \"sinker\",\n",
    "    \"SL\": \"slider\",\n",
    "    \"CU\": \"curveball\",\n",
    "    \"KC\": \"knuckle-curve\",\n",
    "    \"EP\": \"eephus\",\n",
    "    \"CH\": \"changeup\",\n",
    "    \"SC\": \"screwball\",\n",
    "    \"KN\": \"knuckleball\",\n",
    "    \"UN\": \"unidentified\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Translate the `pitchType` column into its longer form names\n",
    "* View the counts of each pitch.  \n",
    "    * Instead of just printing the pitch counts.  Create a barplot of these counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus only on predicting some of the major classes of pitches.  Let's filter down to an arbitray list of 3 (`pitches_we_care_about`).\n",
    "\n",
    "* Use the predefined list to filter our dataframe to only `pitchType`s in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches_we_care_about = [\"fastball (four-seam)\", \"changeup\", \"curveball\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the `shape` and `columns` to get a feel for how much data we removed from the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatter plot of `balls` x `strikes` colored by `pitchType`.  What might be a better way to view this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 2 separate barplots (1 for `balls` and 1 for `strikes`) colored by `pitchType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing I take away from these plots is that a four-seam fastball is the favorite pitch no matter what the count is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make a scatterplot of `releaseVelocity` x `spinDir` colored by `pitchType`.\n",
    "* Plot a horizontal line when `spinDir == 180`.\n",
    "* Add transparency to the plot so you can see if an area of the plot is denser or if its just a couple of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a mirror image in this plot... What could explain this and how might we take action on it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new version of spin direction that is a pitch's absolute difference from 180.\n",
    "* Call it `spinMag` for spin magnitude.\n",
    "* Drop `spinDir` from the dataframe\n",
    "* Redo the plot with `spinRate` x `spinMag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data looks linearly separable already... to have a simpler model we might just proceed with these columns only.\n",
    "\n",
    "Advantages of this\n",
    "\n",
    "1. It's simple to explain rather than bringing in all these additional features that are essentially dead weight if we find out we do get good predictions with just these variables.\n",
    "* We can easily plot the decision boundaries if we only have 2 inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the data into `X` and `y`\n",
    "* Only use `spinMag` and `spinRate` as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = _____\n",
    "y = pitch[\"pitchType\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert y to an integer with `[0, 1, 2]` representing each of our classes.  Technically, this model can handle strings as labels, but many other machine learning tools prefer integer. So it's good to practice this step.  `sklearn` provides the [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) for this task, and you can research this on your own (and we'll use it later), but for today let's do a more manual/pure python way of doing this.\n",
    "\n",
    "* Create a dictionary of replacement values\n",
    "* `print` out the y `value_counts` before replacing to ensure we don't make a mistake\n",
    "* Use `replace` to convert the values to our `int` labels\n",
    "* `print` out the y `value_counts` after replacing to ensure we did't make a mistake\n",
    "* `print` out the dictionary to show a legend for the new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform a train/test split\n",
    "    * Use 20% of the data for testing\n",
    "    * Stratify the split by the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit a Support Vector Classifier (`SVC`)\n",
    "    * Use the `'linear'` `kernel`.\n",
    "    * Use 1.0 for the value of `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the model for both your train and test set to diagnose under/overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score:.2f}\")\n",
    "print(f\"Test score: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show a confusion matrix.\n",
    "   * Which classes are most likely to be confused?\n",
    "* Show a classification report.\n",
    "   * What pitch type do we classify with the highest precision? What does that mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - fastball\n",
    "# 1 - changeup\n",
    "# 2 - curveball\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the decision boundary of the model in relation to our spin predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X_train.values\n",
    "y_np = y_train.values\n",
    "\n",
    "plot_decision_regions(X_np, y_np, clf=model, scatter_kwargs={\"alpha\": 0.1})\n",
    "plt.xlabel(\"spinRate\")\n",
    "plt.ylabel(\"spinMag\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "The main hyperparameters we toy with when fitting a `SVC` is the `kernel` and the value of `C`.  The below quotes are from [this article](https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769) which gives a pretty good overview of both of these hyperparameters. Additionally, the article discusses the `degree` (relevant when `kernel` is `'poly'`) and `gamma` (relevant when `kernel` is not `'linear'`).\n",
    "\n",
    "> C is the penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "\n",
    "> Increasing C values may lead to overfitting the training data.\n",
    "\n",
    "When the `kernel` is `'linear'` we won't see a huge effect when varying the value of `C`.  Its effects are more visible in the decision boundary when we use a non-linear kernel.  Because of this, we're going to change the kernel to `'rbf'` without an explanation of what the means at this point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X_train.values\n",
    "y_np = y_train.values\n",
    "\n",
    "\n",
    "cs = [0.1, 1, 10, 100, 1000, 10000]\n",
    "# The above list can be created fancily with the below\n",
    "# Read as: \"go from 10^(-1) to 10^4 in 6 steps\"\n",
    "cs = np.logspace(-1, 4, 6)\n",
    "for c in cs:\n",
    "    model = SVC(kernel=\"rbf\", C=c)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    plot_decision_regions(X_np, y_np, clf=model, scatter_kwargs={\"alpha\": 0.1})\n",
    "    plt.title(f\"C={c}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside about multiclass in `SVC`\n",
    "\n",
    "SVMs can only draw a single decision boundary, which means that they can only separate 2 classes.  So what is `sklearn` doing that allows us to do this 3 class problem?  From [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) we see the below description for the `decision_function_shape` parameter.\n",
    "\n",
    "> **decision_function_shape** `‘ovo’`, `‘ovr’`, `default=’ovr’`\n",
    ">    \n",
    "> Whether to return a one-vs-rest (`‘ovr’`) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (`‘ovo’`) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (`‘ovo’`) is always used as multi-class strategy.\n",
    "\n",
    "### One-vs-One (ovo)\n",
    "\n",
    "In ovo, we just consider 2 classes at a time and then do some math to combine these multiple decision boundaries.\n",
    "\n",
    "For example, in this data we would fit 3 models:\n",
    "* curve vs fastball\n",
    "* curve vs changeup\n",
    "* fastball vs changeup\n",
    "\n",
    "Each of these are then used to make predictions, and we end up with essentially a majority vote like in KNN (this is over simplified but this as a mental model is ok).\n",
    "\n",
    "### One-vs-Rest (ovr)\n",
    "\n",
    "In ovr, we'll just look at one of our classes as the class of interest at a time and build a model for each class.\n",
    "\n",
    "For example, in this data we would fit 3 models:\n",
    "* curve vs not-curve\n",
    "* fastball vs not-fastball\n",
    "* changeup vs not-changeup\n",
    "\n",
    "Again, we'll use these sub-models to essentially vote.  This is where the analogy to voting can fall apart (what if every model predicts the 'not' class? This where some probabilities come into play)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
