{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "challenge.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmPbmjUfVJjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "babb0b9b-c2ce-4903-9023-ba09236191a3"
      },
      "source": [
        "!pip install markovify"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting markovify\n",
            "  Downloading https://files.pythonhosted.org/packages/31/02/7ff79feeaaf67b9a4e01019ff5845213300d743858ad82dfc8852783c2d6/markovify-0.8.2.tar.gz\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 4.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.8.2-cp36-none-any.whl size=18261 sha256=18c60250f5d17b8ad93b1138f5ca520767ffbea93180f87e7f6dba1a08411b71\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/3f/cc/c2750c71a820928e12f9609ff3a99d7b2c0d93eb61b7170189\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.8.2 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qgj6HhsgPZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import markovify"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzzGM0DlYDRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "22c5e429-8c74-49e8-8e5f-5aebda7dbb80"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0FiX24GwtfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b358e14d-68e8-4bc4-e4ae-dfa16e1229ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq6IJOTCxueE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a1af8f1c-8550-4ac9-fd2d-4ee4afb0e72f"
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of 04_02_inferential_statistics_assign.ipynb'\n",
            "'Copy of Practice - Python for data scientists II - accessing data - rest.ipynb'\n",
            "'Copy of Practice - Python for data scientists II - accessing data - scraping.ipynb'\n",
            "'Copy of Practice - Python for data scientists III - eda viz.ipynb'\n",
            "'Deep Learning'\n",
            "'Natural Language Processing'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mXH5GlKgPZx",
        "colab_type": "text"
      },
      "source": [
        "##### Goals\n",
        "* Predict movie genre from conversation\n",
        "* Generate dialogue\n",
        "* Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvAzaaT4gPZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/Natural Language Processing/18754_24465_bundle_archive/movie_lines.txt\", encoding=\"latin-1\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "movie_lines = []\n",
        "\n",
        "for elem in lines:\n",
        "    line_list = elem.strip(\"\\n\").split(\" +++$+++ \")\n",
        "    movie_lines.append(line_list)\n",
        "\n",
        "movie_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdTRPkBgPZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Natural Language Processing/18754_24465_bundle_archive/movie_conversations.txt\", encoding=\"latin-1\"\n",
        ") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "movie_conversations = []\n",
        "\n",
        "for elem in lines:\n",
        "    line_list = elem.strip(\"\\n\").split(\" +++$+++ \")\n",
        "    line_list[-1] = line_list[-1].strip(\"][\").split(\", \")\n",
        "    movie_conversations.append(line_list)\n",
        "\n",
        "    genres = []\n",
        "    for i in line_list[-1]:\n",
        "        i = i.strip(\"'\")\n",
        "        genres.append(i)\n",
        "    line_list[-1] = genres\n",
        "\n",
        "movie_conversations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pX2wCLwigPZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Natural Language Processing/18754_24465_bundle_archive/movie_characters_metadata.txt\", encoding=\"latin-1\"\n",
        ") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "characters = []\n",
        "\n",
        "for elem in lines:\n",
        "    line_list = elem.strip(\"\\n\").split(\" +++$+++ \")\n",
        "    characters.append(line_list)\n",
        "\n",
        "characters = characters[1:]\n",
        "characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsjg8tFQgPaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Natural Language Processing/18754_24465_bundle_archive/movie_titles_metadata.txt\", encoding=\"latin-1\"\n",
        ") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "movie_titles = []\n",
        "\n",
        "for elem in lines:\n",
        "    line_list = elem.strip(\"\\n\").split(\" +++$+++ \")\n",
        "    line_list[-1] = line_list[-1].strip(\"][\").split(\", \")\n",
        "\n",
        "    genres = []\n",
        "    for i in line_list[-1]:\n",
        "        i = i.strip(\"'\")\n",
        "        genres.append(i)\n",
        "    line_list[-1] = genres\n",
        "\n",
        "    movie_titles.append(line_list)\n",
        "\n",
        "movie_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvbb0zqoHjsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLhxKf7lgPaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "48ba892a-a572-4d91-e30e-6f9b5daca4c6"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "movie_d = dict()\n",
        "for movie_title in movie_titles:\n",
        "    small_d = dict()\n",
        "    for conversation in movie_conversations:\n",
        "        if movie_title[0] == conversation[2]:\n",
        "            for line in movie_lines:\n",
        "                if line[0] in conversation[-1]:\n",
        "                    line_list.append(line[-1])\n",
        "    \n",
        "    small_d['title'] = movie_title[1]\n",
        "    small_d['genres'] = movie_title[-1]\n",
        "    small_d['lines'] = line_list\n",
        "    movie_d[movie_title[0]] = small_d\n",
        "    \n",
        "    print(movie_d)\n",
        "    sys.exit()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnGTkJfnEW0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcZZx0TJgPal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre_list = []\n",
        "for k,v in movie_d.items():\n",
        "  for movie in movie_titles:\n",
        "    if movie[0] == k:\n",
        "      genre_list.append(\" \".join(movie[-1]))\n",
        "# for movie_title in movie_titles:\n",
        "#     genre = \" \".join(movie_title[-1])\n",
        "#     genre_list.append(genre)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0ErUESwgPao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnvxoanWauN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dialogue = []\n",
        "for k,v in movie_d.items():\n",
        "  all_dialogue.append(\" \".join(v))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQSAIQQ-gPas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_list = []\n",
        "for dialogue in all_dialogue:\n",
        "    tokenized = sent_tokenize(dialogue)\n",
        "    tokenized_list.append(tokenized)\n",
        "\n",
        "tokenized_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RlBwv0GgPaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for dialogue in tokenized_list:\n",
        "    model = markovify.Text(dialogue, state_size=3)\n",
        "    for i in range(5):\n",
        "        print(model.make_short_sentence(max_chars=200, min_chars=30, tries=100), \"\\n\")\n",
        "    print(\"`\" * 100, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElNu95Z-gPaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(docs):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    preprocessed = []\n",
        "\n",
        "    for doc in docs:\n",
        "        tokenized = word_tokenize(doc)\n",
        "\n",
        "        cleaned = [\n",
        "            stemmer.stem(lemmatizer.lemmatize(token.lower()))\n",
        "            for token in tokenized\n",
        "            if not token.lower() in stopwords.words(\"english\")\n",
        "            if token.isalpha()\n",
        "        ]\n",
        "\n",
        "        untokenized = \" \".join(cleaned)\n",
        "        preprocessed.append(untokenized)\n",
        "\n",
        "    return preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptXyr_zagPa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed = preprocess(all_dialogue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B91EfuVDgPa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(preprocessed, genre_list, test_size=0.3, random_state=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo7OLk9UgPa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "171319c7-4275-4ba0-a2a0-c8bccdefe4db"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100)),\n",
        "])\n",
        "\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.27 s, sys: 64 ms, total: 5.33 s\n",
            "Wall time: 5.35 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzylgnGvgPbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ne5tFwgPbE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f5f68485-8a78-442e-aadc-917c9896b58a"
      },
      "source": [
        "scores = cross_val_score(model, preprocessed, genre_list, \n",
        "                         cv=10, scoring='f1_macro')\n",
        "\n",
        "print(scores.mean())\n",
        "print(scores.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.02540243197310743\n",
            "0.009590448582636583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlEKZWDpgPbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_true = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l2hz5_WgPbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AONVlAJGcYhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}