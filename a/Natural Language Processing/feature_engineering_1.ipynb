{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# nltk.download('gutenberg')\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean the data\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# the Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the cleaned novels. this can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group into sentences\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# combine the sentences from the two novels into one data frame\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns = [\"text\", \"author\"])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid off stop words and punctuation\n",
    "# and lemmatize the tokens\n",
    "for i, sentence in enumerate(sentences[\"text\"]):\n",
    "    sentences.loc[i, \"text\"] = \" \".join(\n",
    "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9261687571265679\n",
      "\n",
      "Test set score: 0.8641025641025641\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.7206385404789054\n",
      "\n",
      "Test set score: 0.7277777777777777\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.7887685290763968\n",
      "\n",
      "Test set score: 0.7893162393162393\n"
     ]
    }
   ],
   "source": [
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text','author'], 1))\n",
    "\n",
    "# We split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "lr_params = {\"penalty\": [\"l1\", \"l2\"]}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfc_params = {\"n_estimators\": [3, 5, 10, 15],\n",
    "              \"max_depth\": [2, 3, 4, 5],\n",
    "              \"min_samples_split\": [3, 5, 7, 9]}\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gbc_params = {\"n_estimators\": [3, 5, 10, 15],\n",
    "              \"max_depth\": [2, 3, 4, 5],\n",
    "              \"min_samples_split\": [3, 5, 7, 9]}\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "clf_lr = GridSearchCV(lr, lr_params, cv=5)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "clf_rfc = GridSearchCV(rfc, rfc_params, cv=5)\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "\n",
    "clf_gbc = GridSearchCV(gbc, gbc_params, cv=5)\n",
    "clf_gbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', clf_lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', clf_rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', clf_gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>29th</th>\n",
       "      <th>29th september</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abbreviation living</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abdication neighbour</th>\n",
       "      <th>abide</th>\n",
       "      <th>abide consequence</th>\n",
       "      <th>abide figure</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand australia</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealous officer</th>\n",
       "      <th>zealous subject</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zealously discharge</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zigzag go</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shall late</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1st  29th  29th september  abbreviation  abbreviation living  abdication  \\\n",
       "0    0     0               0             0                    0           0   \n",
       "1    0     0               0             0                    0           0   \n",
       "2    0     0               0             0                    0           0   \n",
       "3    0     0               0             0                    0           0   \n",
       "4    0     0               0             0                    0           0   \n",
       "\n",
       "   abdication neighbour  abide  abide consequence  abide figure  ...  \\\n",
       "0                     0      0                  0             0  ...   \n",
       "1                     0      0                  0             0  ...   \n",
       "2                     0      0                  0             0  ...   \n",
       "3                     0      0                  0             0  ...   \n",
       "4                     0      0                  0             0  ...   \n",
       "\n",
       "   zealand australia  zealous  zealous officer  zealous subject  zealously  \\\n",
       "0                  0        0                0                0          0   \n",
       "1                  0        0                0                0          0   \n",
       "2                  0        0                0                0          0   \n",
       "3                  0        0                0                0          0   \n",
       "4                  0        0                0                0          0   \n",
       "\n",
       "   zealously discharge  zigzag  zigzag go  \\\n",
       "0                    0       0          0   \n",
       "1                    0       0          0   \n",
       "2                    0       0          0   \n",
       "3                    0       0          0   \n",
       "4                    0       0          0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2     remarkable Alice think way hear Rabbit oh dear  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                         shall late  Carroll  \n",
       "\n",
       "[5 rows x 35313 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9444127708095781\n",
      "\n",
      "Test set score: 0.8662393162393163\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.9723489167616876\n",
      "\n",
      "Test set score: 0.8354700854700855\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8292474344355758\n",
      "\n",
      "Test set score: 0.8153846153846154\n"
     ]
    }
   ],
   "source": [
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text','author'], 1))\n",
    "\n",
    "# We split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
