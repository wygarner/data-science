{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"from sklearn.linear_model import LinearRegression\";\n",
       "                var nbb_formatted_code = \"from sklearn.linear_model import LinearRegression\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"class Markov:\\n    def __init__(self, X, y):\\n        self.X = X\\n        self.y = y\\n        self.model = LinearRegression()\\n        self.model.fit(X, y)\\n        self.predictions = self.model.predict(X)\\n        self.errors = self.y - self.predictions\\n        self.X_const = sm.add_constant(X)\\n        self.lm_results = sm.OLS(y, self.X_const).fit()\\n        self.coefs = self.model.coef_\\n        self.intercepts = self.model.intercept_\\n\\n    def plot_linearity(self):\\n        count = 1\\n        plt.figure(figsize=(25, 15))\\n        for col in self.X.columns:\\n            plt.subplot(len(cols) / 3, len(cols) / 3, count)\\n            plt.scatter(self.X[col], self.predictions)\\n            plt.xlabel(col)\\n            plt.ylabel(\\\"target\\\")\\n            count += 1\\n\\n        plt.tight_layout()\\n        plt.show()\\n\\n    def plot_homoscedasticity(self):\\n        plt.scatter(self.predictions, self.errors)\\n        plt.xlabel(\\\"Predicted\\\")\\n        plt.ylabel(\\\"Residual\\\")\\n        plt.axhline(y=0)\\n        plt.title(\\\"Residual vs. Predicted\\\")\\n        plt.show()\\n\\n    def b_pagan(self):\\n        _, lmp, _, fp = het_breuschpagan(lm_results.resid, X)\\n\\n        return lmp, fp\\n\\n    def get_vifs(self):\\n        vifs = []\\n        for i in range(X_const.shape[1]):\\n            vif = variance_inflation_factor(X_const.values, i)\\n            vifs.append(vif)\\n\\n        return pd.Series(vifs, index=X_const.columns)\\n\\n    def plot_errors(self):\\n        plt.plot(self.errors)\\n        plt.show()\\n\\n    def plot_errors_acf(self):\\n        acf_data = acf(self.errors)\\n\\n        plt.plot(acf_data[1:])\\n        plt.show()\\n\\n    def plot_error_normality(self):\\n        qqplot(lm_results.resid, line=\\\"s\\\")\\n        plt.show()\\n\\n        plt.hist(lm_results.resid)\\n        plt.show()\\n\\n    def shapiro_wilkes(self):\\n        return stats.shapiro(self.lm_results.resid)\";\n",
       "                var nbb_formatted_code = \"class Markov:\\n    def __init__(self, X, y):\\n        self.X = X\\n        self.y = y\\n        self.model = LinearRegression()\\n        self.model.fit(X, y)\\n        self.predictions = self.model.predict(X)\\n        self.errors = self.y - self.predictions\\n        self.X_const = sm.add_constant(X)\\n        self.lm_results = sm.OLS(y, self.X_const).fit()\\n        self.coefs = self.model.coef_\\n        self.intercepts = self.model.intercept_\\n\\n    def plot_linearity(self):\\n        count = 1\\n        plt.figure(figsize=(25, 15))\\n        for col in self.X.columns:\\n            plt.subplot(len(cols) / 3, len(cols) / 3, count)\\n            plt.scatter(self.X[col], self.predictions)\\n            plt.xlabel(col)\\n            plt.ylabel(\\\"target\\\")\\n            count += 1\\n\\n        plt.tight_layout()\\n        plt.show()\\n\\n    def plot_homoscedasticity(self):\\n        plt.scatter(self.predictions, self.errors)\\n        plt.xlabel(\\\"Predicted\\\")\\n        plt.ylabel(\\\"Residual\\\")\\n        plt.axhline(y=0)\\n        plt.title(\\\"Residual vs. Predicted\\\")\\n        plt.show()\\n\\n    def b_pagan(self):\\n        _, lmp, _, fp = het_breuschpagan(lm_results.resid, X)\\n\\n        return lmp, fp\\n\\n    def get_vifs(self):\\n        vifs = []\\n        for i in range(X_const.shape[1]):\\n            vif = variance_inflation_factor(X_const.values, i)\\n            vifs.append(vif)\\n\\n        return pd.Series(vifs, index=X_const.columns)\\n\\n    def plot_errors(self):\\n        plt.plot(self.errors)\\n        plt.show()\\n\\n    def plot_errors_acf(self):\\n        acf_data = acf(self.errors)\\n\\n        plt.plot(acf_data[1:])\\n        plt.show()\\n\\n    def plot_error_normality(self):\\n        qqplot(lm_results.resid, line=\\\"s\\\")\\n        plt.show()\\n\\n        plt.hist(lm_results.resid)\\n        plt.show()\\n\\n    def shapiro_wilkes(self):\\n        return stats.shapiro(self.lm_results.resid)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Markov:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(X, y)\n",
    "        self.predictions = self.model.predict(X)\n",
    "        self.errors = self.y - self.predictions\n",
    "        self.X_const = sm.add_constant(X)\n",
    "        self.lm_results = sm.OLS(y, self.X_const).fit()\n",
    "        self.coefs = self.model.coef_\n",
    "        self.intercepts = self.model.intercept_\n",
    "\n",
    "    def plot_linearity(self):\n",
    "        count = 1\n",
    "        plt.figure(figsize=(25, 15))\n",
    "        for col in self.X.columns:\n",
    "            plt.subplot(len(cols) / 3, len(cols) / 3, count)\n",
    "            plt.scatter(self.X[col], self.predictions)\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel(\"target\")\n",
    "            count += 1\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_homoscedasticity(self):\n",
    "        plt.scatter(self.predictions, self.errors)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Residual\")\n",
    "        plt.axhline(y=0)\n",
    "        plt.title(\"Residual vs. Predicted\")\n",
    "        plt.show()\n",
    "\n",
    "    def b_pagan(self):\n",
    "        _, lmp, _, fp = het_breuschpagan(lm_results.resid, X)\n",
    "\n",
    "        return lmp, fp\n",
    "\n",
    "    def get_vifs(self):\n",
    "        vifs = []\n",
    "        for i in range(X_const.shape[1]):\n",
    "            vif = variance_inflation_factor(X_const.values, i)\n",
    "            vifs.append(vif)\n",
    "\n",
    "        return pd.Series(vifs, index=X_const.columns)\n",
    "\n",
    "    def plot_errors(self):\n",
    "        plt.plot(self.errors)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_errors_acf(self):\n",
    "        acf_data = acf(self.errors)\n",
    "\n",
    "        plt.plot(acf_data[1:])\n",
    "        plt.show()\n",
    "\n",
    "    def plot_error_normality(self):\n",
    "        qqplot(lm_results.resid, line=\"s\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(lm_results.resid)\n",
    "        plt.show()\n",
    "\n",
    "    def shapiro_wilkes(self):\n",
    "        return stats.shapiro(self.lm_results.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"def clean_houses_data(house_prices_df):\\n    house_prices_df = house_prices_df.set_index(\\\"id\\\")\\n\\n    # Log transfrom dataframe\\n    log_df = house_prices_df.copy()\\n    log_df[\\\"log_saleprice\\\"] = np.log(log_df[\\\"saleprice\\\"])\\n    log_df = log_df.drop(columns=[\\\"saleprice\\\"])\\n\\n    # Keep only top correlated columns\\n    corr_df = log_df.corr()[[\\\"log_saleprice\\\"]]\\n    corr_df.columns = [\\\"corr\\\"]\\n    corr_df[\\\"abs_corr\\\"] = corr_df.abs()\\n    top_corrs = corr_df.sort_values(\\\"abs_corr\\\", ascending=False).head(10)\\n    num_cols = log_df.select_dtypes(\\\"number\\\").columns\\n    keep_cols = top_corrs.index\\n    drop_cols = [c for c in num_cols if c not in keep_cols]\\n    log_df = log_df.drop(columns=drop_cols)\\n    log_df\\n\\n    drop_cols = [\\\"poolqc\\\", \\\"alley\\\", \\\"fence\\\", \\\"fireplacequ\\\", \\\"miscfeature\\\"]\\n    log_df = log_df.drop(columns=drop_cols)\\n    log_df = log_df.dropna()\\n\\n    cat_cols = log_df.select_dtypes(\\\"O\\\").copy()\\n    keep_cols = [\\\"exterqual\\\", \\\"bsmtqual\\\", \\\"kitchenqual\\\", \\\"centralair\\\"]\\n    drop_cols = [c for c in cat_cols.columns if c not in keep_cols]\\n\\n    log_df = log_df.drop(columns=drop_cols)\\n\\n    # Encode centralair as binary\\n    log_df[\\\"centralair\\\"] = (log_df[\\\"centralair\\\"] == \\\"Y\\\").astype(int)\\n\\n    # Encode qual columns as ordinal\\n    quality_map = {\\\"Fa\\\": 1, \\\"TA\\\": 2, \\\"Gd\\\": 3, \\\"Ex\\\": 4}\\n    log_df[[\\\"exterqual\\\", \\\"bsmtqual\\\", \\\"kitchenqual\\\"]] = log_df[\\n        [\\\"exterqual\\\", \\\"bsmtqual\\\", \\\"kitchenqual\\\"]\\n    ].replace(quality_map)\\n\\n    return log_df\";\n",
       "                var nbb_formatted_code = \"def clean_houses_data(house_prices_df):\\n    house_prices_df = house_prices_df.set_index(\\\"id\\\")\\n\\n    # Log transfrom dataframe\\n    log_df = house_prices_df.copy()\\n    log_df[\\\"log_saleprice\\\"] = np.log(log_df[\\\"saleprice\\\"])\\n    log_df = log_df.drop(columns=[\\\"saleprice\\\"])\\n\\n    # Keep only top correlated columns\\n    corr_df = log_df.corr()[[\\\"log_saleprice\\\"]]\\n    corr_df.columns = [\\\"corr\\\"]\\n    corr_df[\\\"abs_corr\\\"] = corr_df.abs()\\n    top_corrs = corr_df.sort_values(\\\"abs_corr\\\", ascending=False).head(10)\\n    num_cols = log_df.select_dtypes(\\\"number\\\").columns\\n    keep_cols = top_corrs.index\\n    drop_cols = [c for c in num_cols if c not in keep_cols]\\n    log_df = log_df.drop(columns=drop_cols)\\n    log_df\\n\\n    drop_cols = [\\\"poolqc\\\", \\\"alley\\\", \\\"fence\\\", \\\"fireplacequ\\\", \\\"miscfeature\\\"]\\n    log_df = log_df.drop(columns=drop_cols)\\n    log_df = log_df.dropna()\\n\\n    cat_cols = log_df.select_dtypes(\\\"O\\\").copy()\\n    keep_cols = [\\\"exterqual\\\", \\\"bsmtqual\\\", \\\"kitchenqual\\\", \\\"centralair\\\"]\\n    drop_cols = [c for c in cat_cols.columns if c not in keep_cols]\\n\\n    log_df = log_df.drop(columns=drop_cols)\\n\\n    # Encode centralair as binary\\n    log_df[\\\"centralair\\\"] = (log_df[\\\"centralair\\\"] == \\\"Y\\\").astype(int)\\n\\n    # Encode qual columns as ordinal\\n    quality_map = {\\\"Fa\\\": 1, \\\"TA\\\": 2, \\\"Gd\\\": 3, \\\"Ex\\\": 4}\\n    log_df[[\\\"exterqual\\\", \\\"bsmtqual\\\", \\\"kitchenqual\\\"]] = log_df[\\n        [\\\"exterqual\\\", \\\"bsmtqual\\\", \\\"kitchenqual\\\"]\\n    ].replace(quality_map)\\n\\n    return log_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_houses_data(house_prices_df):\n",
    "    house_prices_df = house_prices_df.set_index(\"id\")\n",
    "\n",
    "    # Log transfrom dataframe\n",
    "    log_df = house_prices_df.copy()\n",
    "    log_df[\"log_saleprice\"] = np.log(log_df[\"saleprice\"])\n",
    "    log_df = log_df.drop(columns=[\"saleprice\"])\n",
    "\n",
    "    # Keep only top correlated columns\n",
    "    corr_df = log_df.corr()[[\"log_saleprice\"]]\n",
    "    corr_df.columns = [\"corr\"]\n",
    "    corr_df[\"abs_corr\"] = corr_df.abs()\n",
    "    top_corrs = corr_df.sort_values(\"abs_corr\", ascending=False).head(10)\n",
    "    num_cols = log_df.select_dtypes(\"number\").columns\n",
    "    keep_cols = top_corrs.index\n",
    "    drop_cols = [c for c in num_cols if c not in keep_cols]\n",
    "    log_df = log_df.drop(columns=drop_cols)\n",
    "    log_df\n",
    "\n",
    "    drop_cols = [\"poolqc\", \"alley\", \"fence\", \"fireplacequ\", \"miscfeature\"]\n",
    "    log_df = log_df.drop(columns=drop_cols)\n",
    "    log_df = log_df.dropna()\n",
    "\n",
    "    cat_cols = log_df.select_dtypes(\"O\").copy()\n",
    "    keep_cols = [\"exterqual\", \"bsmtqual\", \"kitchenqual\", \"centralair\"]\n",
    "    drop_cols = [c for c in cat_cols.columns if c not in keep_cols]\n",
    "\n",
    "    log_df = log_df.drop(columns=drop_cols)\n",
    "\n",
    "    # Encode centralair as binary\n",
    "    log_df[\"centralair\"] = (log_df[\"centralair\"] == \"Y\").astype(int)\n",
    "\n",
    "    # Encode qual columns as ordinal\n",
    "    quality_map = {\"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4}\n",
    "    log_df[[\"exterqual\", \"bsmtqual\", \"kitchenqual\"]] = log_df[\n",
    "        [\"exterqual\", \"bsmtqual\", \"kitchenqual\"]\n",
    "    ].replace(quality_map)\n",
    "\n",
    "    return log_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-statistics for each variable or the p values from the t tests should be included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'weatherinszeged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "weather_df = pd.read_sql_query('select * from weatherinszeged',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.288</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.288</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.949e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 08 Apr 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:03:52</td>     <th>  Log-Likelihood:    </th> <td>-1.7046e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 96453</td>      <th>  AIC:               </th>  <td>3.409e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 96450</td>      <th>  BIC:               </th>  <td>3.409e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>    2.4381</td> <td>    0.021</td> <td>  115.948</td> <td> 0.000</td> <td>    2.397</td> <td>    2.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>humidity</th>  <td>   -3.0292</td> <td>    0.024</td> <td> -126.479</td> <td> 0.000</td> <td>   -3.076</td> <td>   -2.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>windspeed</th> <td>   -0.1193</td> <td>    0.001</td> <td> -176.164</td> <td> 0.000</td> <td>   -0.121</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3935.747</td> <th>  Durbin-Watson:     </th> <td>   0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4613.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.478</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.484</td>  <th>  Cond. No.          </th> <td>    88.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.288\n",
       "Model:                            OLS   Adj. R-squared:                  0.288\n",
       "Method:                 Least Squares   F-statistic:                 1.949e+04\n",
       "Date:                Wed, 08 Apr 2020   Prob (F-statistic):               0.00\n",
       "Time:                        19:03:52   Log-Likelihood:            -1.7046e+05\n",
       "No. Observations:               96453   AIC:                         3.409e+05\n",
       "Df Residuals:                   96450   BIC:                         3.409e+05\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.4381      0.021    115.948      0.000       2.397       2.479\n",
       "humidity      -3.0292      0.024   -126.479      0.000      -3.076      -2.982\n",
       "windspeed     -0.1193      0.001   -176.164      0.000      -0.121      -0.118\n",
       "==============================================================================\n",
       "Omnibus:                     3935.747   Durbin-Watson:                   0.267\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4613.311\n",
       "Skew:                          -0.478   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.484   Cond. No.                         88.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = weather_df[['humidity','windspeed']]\n",
    "y = weather_df['apparenttemperature'] - weather_df['temperature']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "* Coefs are statistically siginificant\n",
    "* Expecations align.\n",
    "* 1 point increase in humidity results in a ~3 point decrease in the target. 0.12 points for 1 point of windspeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "house_prices_df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"houses = clean_houses_data(house_prices_df)\\nX = houses.drop(columns=[\\\"log_saleprice\\\"])\\ny = houses[\\\"log_saleprice\\\"]\\nhouse_markov = Markov(X, y)\";\n",
       "                var nbb_formatted_code = \"houses = clean_houses_data(house_prices_df)\\nX = houses.drop(columns=[\\\"log_saleprice\\\"])\\ny = houses[\\\"log_saleprice\\\"]\\nhouse_markov = Markov(X, y)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "houses = clean_houses_data(house_prices_df)\n",
    "X = houses.drop(columns=[\"log_saleprice\"])\n",
    "y = houses[\"log_saleprice\"]\n",
    "house_markov = Markov(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>log_saleprice</td>  <th>  R-squared:         </th> <td>   0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   461.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 08 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:46:31</td>     <th>  Log-Likelihood:    </th> <td>  552.19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1338</td>      <th>  AIC:               </th> <td>  -1076.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1324</td>      <th>  BIC:               </th> <td>  -1004.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    6.2533</td> <td>    0.714</td> <td>    8.760</td> <td> 0.000</td> <td>    4.853</td> <td>    7.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th>  <td>    0.0785</td> <td>    0.006</td> <td>   12.951</td> <td> 0.000</td> <td>    0.067</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>    <td>    0.0009</td> <td>    0.000</td> <td>    3.476</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th> <td>    0.0012</td> <td>    0.000</td> <td>    3.723</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterqual</th>    <td>    0.0192</td> <td>    0.013</td> <td>    1.465</td> <td> 0.143</td> <td>   -0.007</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bsmtqual</th>     <td>    0.0461</td> <td>    0.011</td> <td>    4.199</td> <td> 0.000</td> <td>    0.025</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totalbsmtsf</th>  <td>-1.107e-06</td> <td> 2.68e-05</td> <td>   -0.041</td> <td> 0.967</td> <td>-5.37e-05</td> <td> 5.14e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>centralair</th>   <td>    0.1891</td> <td>    0.023</td> <td>    8.176</td> <td> 0.000</td> <td>    0.144</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firstflrsf</th>   <td>    0.0001</td> <td> 2.82e-05</td> <td>    4.481</td> <td> 0.000</td> <td>  7.1e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>    <td>    0.0002</td> <td> 1.39e-05</td> <td>   16.037</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fullbath</th>     <td>   -0.0121</td> <td>    0.012</td> <td>   -1.002</td> <td> 0.316</td> <td>   -0.036</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kitchenqual</th>  <td>    0.0440</td> <td>    0.011</td> <td>    4.063</td> <td> 0.000</td> <td>    0.023</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagecars</th>   <td>    0.0638</td> <td>    0.014</td> <td>    4.611</td> <td> 0.000</td> <td>    0.037</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagearea</th>   <td> 2.728e-05</td> <td> 4.47e-05</td> <td>    0.610</td> <td> 0.542</td> <td>-6.04e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>875.356</td> <th>  Durbin-Watson:     </th> <td>   2.028</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>33512.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.477</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>27.012</td>  <th>  Cond. No.          </th> <td>5.90e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.9e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          log_saleprice   R-squared:                       0.819\n",
       "Model:                            OLS   Adj. R-squared:                  0.817\n",
       "Method:                 Least Squares   F-statistic:                     461.6\n",
       "Date:                Wed, 08 Apr 2020   Prob (F-statistic):               0.00\n",
       "Time:                        19:46:31   Log-Likelihood:                 552.19\n",
       "No. Observations:                1338   AIC:                            -1076.\n",
       "Df Residuals:                    1324   BIC:                            -1004.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            6.2533      0.714      8.760      0.000       4.853       7.654\n",
       "overallqual      0.0785      0.006     12.951      0.000       0.067       0.090\n",
       "yearbuilt        0.0009      0.000      3.476      0.001       0.000       0.001\n",
       "yearremodadd     0.0012      0.000      3.723      0.000       0.001       0.002\n",
       "exterqual        0.0192      0.013      1.465      0.143      -0.007       0.045\n",
       "bsmtqual         0.0461      0.011      4.199      0.000       0.025       0.068\n",
       "totalbsmtsf  -1.107e-06   2.68e-05     -0.041      0.967   -5.37e-05    5.14e-05\n",
       "centralair       0.1891      0.023      8.176      0.000       0.144       0.234\n",
       "firstflrsf       0.0001   2.82e-05      4.481      0.000     7.1e-05       0.000\n",
       "grlivarea        0.0002   1.39e-05     16.037      0.000       0.000       0.000\n",
       "fullbath        -0.0121      0.012     -1.002      0.316      -0.036       0.012\n",
       "kitchenqual      0.0440      0.011      4.063      0.000       0.023       0.065\n",
       "garagecars       0.0638      0.014      4.611      0.000       0.037       0.091\n",
       "garagearea    2.728e-05   4.47e-05      0.610      0.542   -6.04e-05       0.000\n",
       "==============================================================================\n",
       "Omnibus:                      875.356   Durbin-Watson:                   2.028\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            33512.857\n",
       "Skew:                          -2.477   Prob(JB):                         0.00\n",
       "Kurtosis:                      27.012   Cond. No.                     5.90e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.9e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"lm_results= house_markov.lm_results\\nlm_results.summary()\";\n",
       "                var nbb_formatted_code = \"lm_results = house_markov.lm_results\\nlm_results.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_results = house_markov.lm_results\n",
    "lm_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"X = houses.drop(columns=[\\\"log_saleprice\\\",'fullbath','garagearea','totalbsmtsf','exterqual'])\\ny = houses[\\\"log_saleprice\\\"]\\nhouse_markov = Markov(X, y)\";\n",
       "                var nbb_formatted_code = \"X = houses.drop(\\n    columns=[\\\"log_saleprice\\\", \\\"fullbath\\\", \\\"garagearea\\\", \\\"totalbsmtsf\\\", \\\"exterqual\\\"]\\n)\\ny = houses[\\\"log_saleprice\\\"]\\nhouse_markov = Markov(X, y)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = houses.drop(\n",
    "    columns=[\"log_saleprice\", \"fullbath\", \"garagearea\", \"totalbsmtsf\", \"exterqual\"]\n",
    ")\n",
    "y = houses[\"log_saleprice\"]\n",
    "house_markov = Markov(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>log_saleprice</td>  <th>  R-squared:         </th> <td>   0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   666.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 08 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:48:10</td>     <th>  Log-Likelihood:    </th> <td>  550.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1338</td>      <th>  AIC:               </th> <td>  -1081.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1328</td>      <th>  BIC:               </th> <td>  -1029.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    6.2782</td> <td>    0.674</td> <td>    9.311</td> <td> 0.000</td> <td>    4.955</td> <td>    7.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th>  <td>    0.0806</td> <td>    0.006</td> <td>   13.883</td> <td> 0.000</td> <td>    0.069</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>    <td>    0.0009</td> <td>    0.000</td> <td>    3.643</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th> <td>    0.0012</td> <td>    0.000</td> <td>    3.824</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bsmtqual</th>     <td>    0.0474</td> <td>    0.011</td> <td>    4.365</td> <td> 0.000</td> <td>    0.026</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>centralair</th>   <td>    0.1884</td> <td>    0.023</td> <td>    8.194</td> <td> 0.000</td> <td>    0.143</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firstflrsf</th>   <td>    0.0001</td> <td> 1.44e-05</td> <td>    8.980</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>    <td>    0.0002</td> <td>  1.2e-05</td> <td>   18.027</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kitchenqual</th>  <td>    0.0502</td> <td>    0.010</td> <td>    4.933</td> <td> 0.000</td> <td>    0.030</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagecars</th>   <td>    0.0691</td> <td>    0.010</td> <td>    7.212</td> <td> 0.000</td> <td>    0.050</td> <td>    0.088</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>841.968</td> <th>  Durbin-Watson:     </th> <td>   2.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>29202.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.367</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>25.392</td>  <th>  Cond. No.          </th> <td>5.24e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.24e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          log_saleprice   R-squared:                       0.819\n",
       "Model:                            OLS   Adj. R-squared:                  0.818\n",
       "Method:                 Least Squares   F-statistic:                     666.6\n",
       "Date:                Wed, 08 Apr 2020   Prob (F-statistic):               0.00\n",
       "Time:                        19:48:10   Log-Likelihood:                 550.32\n",
       "No. Observations:                1338   AIC:                            -1081.\n",
       "Df Residuals:                    1328   BIC:                            -1029.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            6.2782      0.674      9.311      0.000       4.955       7.601\n",
       "overallqual      0.0806      0.006     13.883      0.000       0.069       0.092\n",
       "yearbuilt        0.0009      0.000      3.643      0.000       0.000       0.001\n",
       "yearremodadd     0.0012      0.000      3.824      0.000       0.001       0.002\n",
       "bsmtqual         0.0474      0.011      4.365      0.000       0.026       0.069\n",
       "centralair       0.1884      0.023      8.194      0.000       0.143       0.233\n",
       "firstflrsf       0.0001   1.44e-05      8.980      0.000       0.000       0.000\n",
       "grlivarea        0.0002    1.2e-05     18.027      0.000       0.000       0.000\n",
       "kitchenqual      0.0502      0.010      4.933      0.000       0.030       0.070\n",
       "garagecars       0.0691      0.010      7.212      0.000       0.050       0.088\n",
       "==============================================================================\n",
       "Omnibus:                      841.968   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            29202.077\n",
       "Skew:                          -2.367   Prob(JB):                         0.00\n",
       "Kurtosis:                      25.392   Cond. No.                     5.24e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.24e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"lm_results = house_markov.lm_results\\nlm_results.summary()\";\n",
       "                var nbb_formatted_code = \"lm_results = house_markov.lm_results\\nlm_results.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_results = house_markov.lm_results\n",
    "lm_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (data_science_env)",
   "language": "python",
   "name": "data_science-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
